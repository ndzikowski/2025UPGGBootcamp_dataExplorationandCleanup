---
title: "2025 UPGG Bootcamp - Data Exploration & Cleanup"
author: "Erick Figueroa-Ildefonso and Natalie Dzikowski"
date: "2025-08-21"
output: html_document
editor_options: 
  markdown: 
    wrap: 100
---

Learning objectives:

-   Download and inspect data using R
-   Learn how to use Tidyverse functions
-   Explore data in a scientifically motivated way
-   Organize and manipulate data in preparation for summary and visualization

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Exploration and Clean-Up

The first half of this morning, we'll go through the package called `Tidyverse` which you all should
have installed as part of the lesson yesterday.

## Tidyverse (\~30 min)

What is [Tidyverse](https://www.tidyverse.org/)? Tidyverse is a collection of R packages that had
been designed and developed for data science. R is not a new language, and Tidyverse's philosophy is
about reducing redundancy and improving coding style to be cleaner and more intuitive.

First, even though we have all installed the package Tidyverse, the package has yet been loaded into
your environment. You won't have access to Tidyverse's functions unless you run `library(tidyverse)`

```{r}
library(tidyverse)
```

Tidyverse is a literal gold mine, and there's no way we're going to cover everything in just a few
hours! We're going to go through a few functions that are particularly useful and most commonly
used.

### Tibble

A `tibble` is Tidyverse's attempt to improve on `data frame`. In general, they are about equivalent
in terms of function. For the sake of this lesson, we'll use `tibble` because any Tidyverse's
`readr` function would output a `tibble` by default. Don't worry about the differences - they are,
for the most parts, interchangeable.

You can convert a preexisting data frame into a tibble.

```{r}
my_tib <- as_tibble(mtcars) # Converting a data frame to tibble
my_tib # looks very similar to data frame
```

Another way to create a tibble. Key components are column names and values. Each column can only
contain one data type.

```{r}
my_tib2 <- tibble(name = c("Josh", "Peter"),
                  income = c(100000000, 20))
my_tib2
```

Conventionally, for data frames and tibbles, each row contains observations, each column contains
variables, and each cell contains values.

```{r}
my_tib
```

Subsetting, same as data frame

```{r}
tb <- tibble(
  x = runif(5),
  y = rnorm(5))
# Extract by name 1
tb$x
# Extract by name 2
tb[["x"]]
# Extract by column index 1
tb[[1]]
```

```{r}
# If have time, example of differences between data frame vs tibble
mtcars[,1]
as_tibble(mtcars)[,1]
```

```{r}
class(tb)
```

## Dplyr - Data Manipulation

Tidyverse is a meta-package, meaning it includes multiple packages within it. One of them is `dplyr`
which contains functions involving common data manipulation tasks. Note that these functions
generally also work on data frames, not just tibble.

```{r}
table1 # comes with dplyr
```

### Select

Select columns you want from a tibble.

```{r}
select(table1, year)
```

> Note how you can refer to the column name directly without having to use "" or put it adjacent to
> variable name (i.e. table1\$year)? That's the power of Tidyverse!

Select multiple columns

```{r}
select(table1, country, year)
```

Use `-` to exclude columns.

```{r}
select(table1, -year)
```

### Filter

Compare to base R, tidyverse is trying to reduce redundancy of repeating the name of the variable.

In base R, if you want to look for observations from year 2000:

```{r}
table1[table1$year == 2000,]
```

See how `table1` has to be called multiple times? That's redundancy!! Using `filter` reduces
redundancy in your code. It filters for observations that match the logical operation you parse in.

```{r}
filter(table1, year == 2000) # Using dplyr is much cleaner
```

Nesting different functions become wordy and unintuitive to write and read. Tidyverse tries to
mitigate this problem by introducing its own grammar structure (which is now introduced in base R as
well) that helps organizing the code corresponding to how your brain would normally work.
Sequentiality is important.

```{r}
select(filter(table1, year == 2000), country) # Nesting filter within select is unintuitive because filter is interpreted first, then select
```

Instead, you can use `pipe`, this is now even cleaner than before, you only have to type the name
`table1` once. The symbol for `pipe` is `%>%`. The way `pipe` works is that, it will use the output
of the function before `pipe` as the **first argument** of the function after `pipe`. Therefore,
most `dplyr` functions put the option for a tibble as first argument, so you can keep sending the
tibble down the `pipe` chain. `Pipe` is not limited to just Tidyverse functions.

```{r}
# Now, the sequence of steps becomes more intuitive; filter and then select!
table1 %>%
    filter(year == 2000) %>%
    select(country)
```

### Mutate

Mutate is a very powerful function. It manipulates columns and can add columns as well. You can
directly pull information from different column within `mutate()`.

```{r}
table1 %>%
    mutate(rate = cases / population * 10000) # This doesn't happen in-place. Don't forget to assign it to the same variable or new variable. 
```

```{r}
table1
```

```{r}
new_table1 <- table1 %>%
    mutate(rate = cases / population * 10000)
new_table1
```

Note on naming columns, you generally don't want to include spaces. Sometimes you have to fix the
column names of data files you download from others, especially if they were made in Excel which
generally doesn't have problem dealing with white spaces between words.

```{r, error=TRUE}
my_tib$miles per gallon
my_tib %>%
    filter(miles per gallon > 10)
```

```{r}
my_tib$'miles per gallon' <- 1:32 
my_tib$'miles per gallon'
```

```{r}
my_tib %>%
    filter('miles per gallon' > 10)
# space has meaning in programming!!!

my_tib$miles_per_gallon <- 1:32 # much better
```

#### Quick lesson on conditionals

You can guide R to perform tasks that depend on a certain condition using `if` statement.

```{r}
if (10 > 5) {
  print("10 is greater than 5")
}
```

You can create a dichotomy of tasks for R using `if` and `else` statement.

```{r}
plant_speed <- 1000
car_speed <- 40

if (plane_speed > car_speed) {
  print("Planes are faster than cars")
} else {
  print("Planes are NOT faster than cars")
}
```

There is a nifty function called `if_else()` that you can use within `mutate()` to create a new
column!

```{r}
table1 %>%
  mutate(size = if_else(population > 1e8, "big", "small"))
```

### Arrange

Arrange helps sorting the rows of a tibble based on a column.

```{r}
table1 %>%
    mutate(rate = cases / population * 10000, .after = year) %>%
    arrange(desc(rate)) # sort rate in descending order
```

### Summarize()

Summarize give you statistics for whatever you want!

```{r}
table1 %>%
    summarize(max = max(cases), mean = mean(cases))
```

### Group_by()

```{r}
table1 %>%
    group_by(year) %>%
    count()
```

`summarize()` is particularly useful in combination with `group_by()`

```{r}
table1 %>%
    group_by(year) %>%
    summarize(max = max(cases), mean = mean(cases))
```

## Tidyr

### Reshape/Pivot data

Yes, data might not be tidy when you obtain it from other labs or download from a database.
Sometimes, however, data **is** tidy, but it is organized in such a way to facilitate other
analyses. You might want to reshape how data looks like to fit your specific analysis. This is where
reshaping a tibble comes in - you can spread one variable across multiple columns, or scatter one
observation across multiple rows.

You can use functions from `tidyr` to deal with these cases! `pivot_longer()` and `pivot_wider()`.

```{r}
table4a
```

1999 and 2000 are recording of the same variable (cases) but from different years. It is intuitive
to place them in different columns next to each other if we want to compare by eyes. But in
plotting, you might want to merge them into one column called "cases".

```{r}
table4a %>%
    pivot_longer(c('1999', '2000'), 
                 names_to = "year", # What should we call the new column that will contain the original names?
                 values_to = "cases") # What should we call the new column that will contain the original values?
```

Note that year is of type `chr`. We can use `mutate()` to convert type from `chr` to `dbl`.

```{r}
table4a %>%
    pivot_longer(c('1999', '2000'), 
                 names_to = "year", # What should we call the new column that will contain the original names?
                 values_to = "cases") %>% # What should we call the new column that will contain the original values? 
    mutate(year = parse_double(year))
```

### Pivot Wider

On the opposite end, you might want to spread cases into two columns, one for each year.

```{r}
table2
```

```{r}
table2 %>%
    pivot_wider(names_from = type, # what should the new column names be
                values_from = count) # where should the values in new column come from
```

## Readr

`readr` contains functions involved in reading different types of data and import into R
environment.

Base R has different read functions as well! For example, `read.table()` is a very versatile read
function for tabular data. We are going to try to read `dummy.csv` file using
`https://github.com/erickfigue/2025_UPGG_Bootcamp_DataExploreInR/raw/main/raw_data/practice.csv`.

```{r}
read.table("https://github.com/erickfigue/2025_UPGG_Bootcamp_DataExploreInR/raw/main/raw_data/practice.csv", sep = ",", header = TRUE)
```

`readr` introduces similar read functions. They generally perform faster and have more consistent
naming scheme. Feel free to get used to using `readr` functions to read files, just make sure you
have the packaged loaded before you do so.

```{r}
# We know the file is in csv format
dummy <- read_csv("https://github.com/erickfigue/2025_UPGG_Bootcamp_DataExploreInR/raw/main/raw_data/practice.csv") # generates tibble by default.
dummy
```

----------------------------------------------------------------------------------------------------

## BREAK

----------------------------------------------------------------------------------------------------

## Blank et al., 2017 Transcriptomics Dataset

As a UPGG student, you might end up dealing with some type of "-omics" dataset (epigenomics,
transcriptomics, proteomics, maybe multiomics!). Today, we'll be exploring and cleaning up a
transcriptomics dataset from the following paper:

[*Translational control of lipogenic enzymes in the cell cycle of synchronous, growing yeast
cells*](https://www.embopress.org/doi/full/10.15252/embj.201695050)

### What was the goal of the study?

The authors were searching for proteins that are under periodic translational control over the
course of the cell cycle in yeast, using the size of the cell as a marker for cell cycle stage.

-   Are there any proteins whose levels change depending on the stage of the cell cycle (a.k.a. the
    size of the cell)?
-   Is the change in protein level due to transcriptional control (at the mRNA level), or
    translational control (at the protein level)?

### Which datasets will we be looking at?

Dataset 1: **A dataframe** of mRNA levels of over 6000 transcripts analyzed in THIS study.
Specifically, the authors took the normalized read counts of each mRNA transcript, at each different
cell size, found the mean read count for each gene across all of the cell sizes, and expressed the
mRNA levels of each gene as a ratio of the level at each cell size over the mean. These ratios were
then log2-transformed.

Dataset 2: **A vector** of 144 transcripts whose levels were found to fluctuate over the course of
the cell cycle, both in this study, and in *Spellman et. al, 1998*. These are the genes under
"periodic transcriptional control".

In addition to these, we will need help from 2 gene annotation files to understand the data.

### Who cares?

RNA sequencing has been fundamental to genomics research. It's very possible you might generate
data like this in your own research. You may be analying changing mRNA levels in the cell due to a
normal cellular process, or due to some genetic, epigenetic, or chemical perturbation you did in an
experiment.

What if you never do RNA sequencing? Still, at some point, you may have to deal with data formatted
in a really similar way (protein levels, fluorescence on DNA microarrays, etc.).

## Load data

We will store the file as a variable first for efficiency, then read in the line of each file using the "read_lines" function. Feel free to load the file using the path as it appears on your local machine; however, in case of any issues, a download link for the data is already provided for you in the code blocks below. 

```{r load data}
library(tidyverse)
mRNA_file <- "https://github.com/ndzikowski/2025UPGGBootcamp_dataExplorationandCleanup/raw/main/rawData/GSE81932_Dataset01.txt.gz"
mRNA_data <- read_lines(mRNA_file)

periodically_expressed_genes_file <- "https://github.com/ndzikowski/2025UPGGBootcamp_dataExplorationandCleanup/raw/main/rawData/GSE81932_Dataset02.txt.gz"
periodically_expressed_genes <- read_lines(periodically_expressed_genes_file)

ribi_annotation_file <- "https://github.com/ndzikowski/2025UPGGBootcamp_dataExplorationandCleanup/raw/main/rawData/ribosome_biogenesis_annotations.txt"

scer_names_estimates_file <- "https://github.com/ndzikowski/2025UPGGBootcamp_dataExplorationandCleanup/raw/main/rawData/scer-mrna-protein-absolute-estimate.txt"
```

## Explore the data

Try "printing" the values contained in the variable `periodically_expressed_genes`.

[@akaike1974]

```{r}
periodically_expressed_genes
print(periodically_expressed_genes)
```

`periodically_expressed_genes` is a "vector" data type. It is similar to an "array" or a "list" in
some other programming languages, BUT R has its own version of "list." Essentially, R has both
"vector" and "list" data types, and they function differently. "Vectors" are what you would think of
when you think of Python's "array" or "list"

```{r}
str(periodically_expressed_genes)
```

`periodically_expressed_genes` is really clean data. What about `mRNA_data`?

```{r}
mRNA_data
```

This one has a header. Luckily, if we turn the file into a tibble, that header will be recognized
immediately.

```{r}
mRNA <- read_tsv(mRNA_file)
```

Remember, the output of many tidyverse functions will automatically be a tibble! Applying read_tsv
to a data file can accomplish this.

Now let's peek inside the ribosome biogenesis annotations:

```{r}
read_lines(ribi_annotation_file, n_max=10)
```

Here, we can see that comments are marked with a "!"

### Exercise: How can we make a tibble that skips these?

*Solution:*

```{r}
ribi_annotation <- read_tsv(ribi_annotation_file, comment = "!")

ribi_annotation
```

What about for the Dryad annotations?

```{r}
read_lines(scer_names_estimates_file, n_max = 10)
```

Skip comments:

```{r}
scer_names_estimates <- read_tsv(scer_names_estimates_file, comment = "#")

scer_names_estimates
```

## What can we learn about the data?

One of the first things you might be curious about is how many transcripts were analyzed in total,
and how many genes ended up making it on the "periodically expressed" list.

How can we get these values?

Here's a really easy, built-in way to do so:

```{r}
length(mRNA_data)
```

There are 6714 lines, so without the header, there are 6713 transcripts.

```{r}
length(periodically_expressed_genes)
```

And 144 genes were periodically expressed.

But we're using tidyverse, so we don't even need `length()`. Just peek at the tibble, the
information is right there!

```{r}
mRNA
```

We just got a decent overview of the data, but can we always be sure that each line corresponds to a
unique gene? What if there are duplicates?

### Exercise: Check whether there are duplicate entries in `mRNA` and in `periodically_expressed_genes`.

*Solution:*

```{r}
n_distinct(mRNA$ORF)

n_distinct(periodically_expressed_genes)
```

Looks like every entry is unique.

## Let's explore our ribi annotation file

Which parts of this dataframe are we interested in?

```{r}
ribi_annotation
```

The datasets in this study identified transcripts by their gene IDs, specific only to *S.
cerevisiae* - these can be found in the column 'Systematic Name/Complex Accession'. The
'Gene/Complex' column provides a more common name for that gene.

Additionally, we have the column "Gene Ontology Term" for each gene, associating it with a
biological process. The file we downloaded was called `ribosome_biogenesis_annotations.txt`, so we'd
probably assume that these are only genes involved in ribosome biogenesis.

Still, let's double check that to be sure!

### Exercise: Inspect `ribi_annotation` and check whether the genes are, for sure, only involved in ribosomal biogenesis.

*Solution:*

```{r}
n_distinct(ribi_annotation$Qualifier)

distinct(ribi_annotation, Qualifier)
```

```{r}
n_distinct(ribi_annotation$`Gene Ontology Term`)

distinct(ribi_annotation, `Gene Ontology Term`)
```

So, clearly, we only have genes involved in ribosome biogenesis.

The most useful part of this annotation file will be to convert the yeast gene IDs into more common
names for downtstream analyses.

### Discussion:

Why do you think we provided 1 argument for the `n_distinct()` function, but 2 arguments for
`distinct()` ?

## Cleaning up the annotation file

### Exercise: Take only the columns we want from the dataframe: the gene names and the systematic IDs.

*Solution:*

```{r}
ribi_annotation_names <- select(ribi_annotation, Gene = "Gene/Complex", SystematicName = "Systematic Name/Complex Accession")

ribi_annotation_names
```

Next, we should check if there are any duplicate gene entries, or if each line is unique.

### Exercise: Check the number of unique gene name/systematic name combinations. Are there duplicates? If yes, create a new dataframe with duplicates removed, and double-check that this was done correctly.

*Solution:*

```{r}
n_distinct(ribi_annotation_names)
```

```{r}
ribi_genes <- distinct(ribi_annotation_names)

ribi_genes

n_distinct(ribi_genes)
```

Looks like our whole dataframe is made up of distinct entries now!

## Which ribosome biogenesis genes are periodically expressed during the cell cycle?

We want to filter `ribi_genes` to only include the ones that appear in the
periodically_expressed_genes, and make this a new dataframe.

```{r}
ribi_genes_periodic <- filter(ribi_genes, SystematicName %in% periodically_expressed_genes)

ribi_genes_periodic
```

We can now see that 34/144 periodically expressed genes are involved in ribosome biogenesis (or that
34/187 ribosome biogenesis genes are periodically expressed during the cell cycle).

**Note:** There are often many ways to arrive at the same solution, even for the same function!

```{r}

ribi_genes_periodic2 <- ribi_genes %>%
    filter(SystematicName %in% periodically_expressed_genes)
```

In this case, would you want to do option 2 from above? Why or why not?

## Did our favorite gene make the cut?

We can also check if our favorite gene is on this list! It would be easy enough to do manually, but
let's pretend our dataframe is still really long...

```{r}
"NUG1" %in% ribi_genes_periodic$Gene
```

It's there! Let's print the line to see what its Systematic Name is.

```{r}
filter(ribi_genes_periodic, Gene == "NUG1")
```

### Exercise: Check whether the gene "RPS6B" is a periodically expressed gene, and try printing its line to see its systematic name.

*Solution:*

```{r}
"RPS6B" %in% ribi_genes_periodic$Gene
```

```{r}
filter(ribi_genes_periodic, Gene == "RPS6B")
```

Oops! That one's not there.

## What about genes with other functions?

Up until now, we were looking only at ribosome biogenesis genes, since that was a major GO term that
came up in the data. What about the genes involved in other biological processes?

Let's read the Dryad file!

The columns `"orf"` and `"gene"` will be useful to us for now.

Let's create a new dataframe with only these columns.

```{r}
scer_gene_names <- select(scer_names_estimates, Gene = gene, SystematicName = orf)
```

### Challenge:

1.  Get the names of genes from the Dryad annotations that are periodically expressed.
2.  Extract only the common gene names from the output of 1.
3.  Is the gene NOP56 on this list?

```{r}
filter(scer_gene_names, SystematicName %in% periodically_expressed_genes)

filter(scer_gene_names, SystematicName %in% periodically_expressed_genes) %>% select(Gene)

filter(scer_gene_names, SystematicName %in% periodically_expressed_genes, Gene == "NOP56")

filter(scer_gene_names, Gene == "NOP56")

"YLR197W" %in% periodically_expressed_genes
```

Looks like NOP56 is not periodically expressed (but it definitely is in the gene annotation file).
To double-check, its systematic name is indeed not in the list of periodically expressed genes.

### Exploring more of the Dryad data

This dataset actually has a lot more interesting information, like mRNA and protein levels for each
gene. To explore these columns, we can use the `arrange()` function. This will allow us to sort the
dataframe according to a variable we're interested in.

```{r}
arrange(scer_names_estimates, gene)
```

The default is ascending order.

```{r}
arrange(scer_names_estimates, gene) %>% tail()
```

What would this do?

```{r}
arrange(scer_names_estimates, desc(gene))
```

What about this?

```{r}
arrange(scer_names_estimates, desc(gene), mrna)
```

Wait, can't we just use `sort()` instead or `arrange()`?

```{r}
arrange(scer_names_estimates, desc(gene), mrna) %>% tail()
```

With `arrange()`, NA values automatically get put the end, regardless of whether you're arranging in
ascending or descending order. This makes removal or data exploration more convenient.

## Let's put the two biggest datasets together

What if our favorite gene is periodically expressed, but it was only identified in the 2017 study,
but not the 1998 study? (This would mean it was never included in `periodically_expressed_genes`).

Well, we have access to all of the mRNA data (\>6000 transcripts), and a comprehensive annotation
set from Dryad. Let's put these two together to see what's happening to ALL of the genes, so then we
can check what's happening to our favorite genes.

There are a bunch of ways to join datasets together on common keys. We can try out a bunch of these
`join` methods and see what we get.

A "key" that both datasets have in common is the "systematic name". However, this list of gene IDs
is labeled "SystematicName" in the Dryad annotations, but labeled "ORF" in Dataset01 (mRNA). Let's
change the name of one of the columns to match:

```{r}
names(mRNA)[1] <- "SystematicName"

mRNA
```

Let's perform a `left_join()` on the two datasets, following this format:

`joined_df <- left_join(x, y, by = "key")`

This will take all rows of dataframe 'x', & keep all of the columns in 'x', while merging dataframe
'y' on the desired key and appending columns from 'y', with values that correctly correspond to each
key.

That might sound confusing at first, so let's just see what happens:

```{r}
mRNA_named <- left_join(mRNA, scer_gene_names, by = "SystematicName")

mRNA_named
```

This will let us search (via their common names) whether our favorite genes are indeed periodically
expressed. For example:

```{r}
filter(mRNA_named, Gene %in% c("ACT1", "NOP16", "NOP56"))
```

There are definitely some fluctuations in mRNA. Interesting! Maybe they just didn't make the cut
according to the parameters/thresholds used by the authors; or, maybe they just weren't identified
in both the 2017 and 1998 papers. Following the authors' methodology, your data is now set up for
you to find the culprit (on your own time, if you're interested).

## Saving your work

You've done all this work - be sure to save it now!

```{r}
write_csv(mRNA_named, "../processed_files/mRNA_data_with_gene_names.csv")
```

## Reshaping tibbles

Sometimes, we might want to reshape a tibble to make it better formatted

for plotting/visualization later on. Dataset01 can be reshaped into a longer, and less wide, format:

```{r}
mRNA_named

pivot_longer(mRNA_named,cols = ends_with("fL"),
    names_to = "Vol_fL",
        values_to="log2_ratio")
```

What do you notice changed about Dataset01?

We might run into issues if all of the cell volumes are formatted as a "(integer) fL".

## Exercise: Look through your cheat sheets. What function(s) can we pipe to remove the " fL" from every value in the "Vol_fL" column?

*Solution:*

```{r}
pivot_longer(mRNA_named,cols = ends_with("fL"),
    names_to = "Vol_fL",
        values_to="log2_ratio") %>%
            mutate(Vol_fL = parse_double(str_remove(Vol_fL, " fL")))
```

This looks easier to work with now. Let's save it to a new tibble:

```{r}
mRNA_data_long <- 
pivot_longer(mRNA_named,cols = ends_with("fL"), 
    names_to = "Vol_fL", 
        values_to="log2_ratio") %>%
            mutate(Vol_fL = parse_double(str_remove(Vol_fL, " fL")))
```

Now, we can easily pick 3 genes we're most interested in, and plot their fluctuating mRNA levels
over the course of the cell cycle!

Let's save that information into a small dataframe, and then Kayla and Gabe will guide you through
plotting.

```{r}
mRNA_data_3genes <- filter(mRNA_data_long, Gene %in% c("ACT1","NOP16","NOP56"))
```

```{r}
write_csv(mRNA_data_3genes, "../processed_files/mRNA_data_3genes.csv")
```

# \## Questions?
